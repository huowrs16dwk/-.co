
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/bundle.css">
    <title>nixos docker llama-gpt</title>
  </head>
  <body>
    <div class="wrapper">
    
<article>

<h1>nixos docker llama-gpt</h1>
<p>Configuring nixos can be difficult because the parameters are not always obvious.  This assumes an x86 cpu and an nvidia gpu with cuda 12 support</p>
<h2>configuring nixos</h2>
<p>Add the following to /etc/nixos/configuration.nix</p>
<pre><code>
  environment.systemPackages = with pkgs; [
    ...

    # gpu
    cudatoolkit
  ];


  # nvidia

  hardware.nvidia.modesetting.enable = true;
  hardware.opengl.enable = true;
  hardware.opengl.driSupport32Bit = true;
  services.xserver.videoDrivers = [ &quot;nvidia&quot; ];
  nixpkgs.config.cudaSupport = true;

  # docker

  virtualisation.docker.enable = true;
  virtualisation.docker.enableNvidia = true;
  virtualisation.docker.extraOptions = &quot;--add-runtime nvidia=/run/current-system/sw/bin/nvidia-container-runtime&quot;;

</code></pre>
<p>The upgrade will potentially take a very long time as it needs to compile several modules.
You will need to reboot after the upgrade.</p>
<pre><code>sudo nixos-rebuild switch &amp;&amp; sudo reboot
</code></pre>
<h2>testing</h2>
<p>Ensure that nvidia-smi command works on the host machine and shows CUDA Version 12.x</p>
<pre><code>nvidia-smi
</code></pre>
<p>Ensure the docker nvidia runtime is working correctly and that nvidia-smi can be run from inside a container</p>
<pre><code>docker run --rm -it --gpus all nvidia/cuda:12.2.0-devel-ubuntu20.04 nvidia-smi
</code></pre>
<h2>running the project</h2>
<pre><code>git clone https://github.com/getumbrel/llama-gpt
cd llama-gpt
./run.sh --model 7b --with-cuda
</code></pre>
<p>Now access port 3000 from a browser.</p>


</article>


    </div>

    <div class="footer">


<nav>
  <ul>
    
    <li><a href="/posts/ghidra-debugging-with-lldb/"><span class="date">[ 2023-11-18 ]</span> ghidra debugging with lldb</a></li>
    
    <li><a href="/posts/practical-nix-flakes/"><span class="date">[ 2023-11-09 ]</span> practical nix flakes</a></li>
    
    <li><a href="/posts/nixos-docker-llama-gpt/"><span class="date">[ 2023-10-07 ]</span> nixos docker llama-gpt</a></li>
    
    <li><a href="/posts/archinstall-with-encrypted-btrfs/"><span class="date">[ 2023-09-14 ]</span> archinstall with encrypted btrfs</a></li>
    
    <li><a href="/posts/encrypted-usb-sticks/"><span class="date">[ 2023-08-25 ]</span> encrypted usb sticks</a></li>
    
    <li><a href="/posts/home-lab-hybrid-cloud-setup/"><span class="date">[ 2023-08-23 ]</span> home lab hybrid cloud setup</a></li>
    
    <li><a href="/posts/vpn-sharing/"><span class="date">[ 2023-08-20 ]</span> vpn sharing</a></li>
    
    <li><a href="/posts/command-line-tutorial/"><span class="date">[ 2023-08-15 ]</span> command line tutorial</a></li>
    
    <li><a href="/posts/connecting-to-github-securely/"><span class="date">[ 2023-07-30 ]</span> connecting to github securely</a></li>
    
  </ul>
</nav>


<div class="home">
  <a href="/">浪人</a>
</div>

</div>

  </body>
</html>
